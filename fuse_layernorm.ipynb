{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch.fx\n",
    "from segformer import MixVisionTransformer\n",
    "from fusion import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fcd4c44aad0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conv_bn_pairs(traced_model):\n",
    "    conv_bn_pairs = []\n",
    "    prev_node = None\n",
    "    module_dict = dict(traced_model.named_modules())  # Get all modules with proper dot-separated names\n",
    "\n",
    "    for node in traced_model.graph.nodes:\n",
    "        if node.op == 'call_module':\n",
    "            module = module_dict[node.target]\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                prev_node = node\n",
    "            elif isinstance(module, nn.BatchNorm2d) and prev_node:\n",
    "                # Use the full dot-separated module names\n",
    "                conv_name = node.target  # Already in dot notation\n",
    "                bn_name = prev_node.target  # Already in dot notation\n",
    "                conv_bn_pairs.append((bn_name, conv_name))  # Keep order (conv, bn)\n",
    "                prev_node = None\n",
    "    return conv_bn_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edmond/anaconda3/envs/virenv1/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/home/edmond/anaconda3/envs/virenv1/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv bn pairs: 104, Con extracted: 104\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnext101_64x4d(pretrained=False)\n",
    "traced = torch.fx.symbolic_trace(model) \n",
    "conv_bn_pairs = find_conv_bn_pairs(traced)\n",
    "print(f\"Conv bn pairs: {len(conv_bn_pairs)}, Con extracted: {len(extract_layers_hierarchy(model))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing Layers: 100%|██████████| 99/99 [00:00<00:00, 552.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion completed: BatchNorm fusion finished. 12608 parameters were reduced after fusion. Feasible fused: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fused_model = deepcopy(model)\n",
    "fuseable_layer_attributes = extract_layers_hierarchy(model)\n",
    "# fuseable_layer_attributes = conv_bn_pairs\n",
    "\n",
    "params_reduced = 0\n",
    "feasible_cnt = 0\n",
    "for fuseable_layer_attribute in tqdm(fuseable_layer_attributes, desc=\"Fusing Layers\"):\n",
    "    try:\n",
    "        conv_layer = get_layer_by_path(fused_model, fuseable_layer_attribute[0])\n",
    "        bn_layer = get_layer_by_path(fused_model, fuseable_layer_attribute[1])\n",
    "        if isinstance(bn_layer, nn.Identity):\n",
    "            continue\n",
    "        # Fuse conv and bn layers\n",
    "        fused_layer = fuse_conv_and_bn(conv_layer, bn_layer)\n",
    "        num_conv_params = sum(p.numel() for p in conv_layer.parameters())\n",
    "        num_bn_params = sum(p.numel() for p in bn_layer.parameters())\n",
    "        num_fused_params = sum(p.numel() for p in fused_layer.parameters())\n",
    "        params_reduced += num_conv_params + num_bn_params - num_fused_params\n",
    "        rsetattr(fused_model, fuseable_layer_attribute[0], fused_layer)\n",
    "        rsetattr(fused_model, fuseable_layer_attribute[1], nn.Identity())\n",
    "        feasible_cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"Fusion completed: BatchNorm fusion finished. {params_reduced} parameters were reduced after fusion. Feasible fused: {feasible_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing Layers: 100%|██████████| 200/200 [00:01<00:00, 168.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion completed: BatchNorm fusion finished. 13888 parameters were reduced after fusion. Feasible fused: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fused_model1 = deepcopy(model)\n",
    "# fuseable_layer_attributes = extract_layers_hierarchy(model)\n",
    "fuseable_layer_attributes = conv_bn_pairs\n",
    "\n",
    "params_reduced = 0\n",
    "feasible_cnt = 0\n",
    "for fuseable_layer_attribute in tqdm(fuseable_layer_attributes, desc=\"Fusing Layers\"):\n",
    "    try:\n",
    "        conv_layer = get_layer_by_path(fused_model1, fuseable_layer_attribute[0])\n",
    "        bn_layer = get_layer_by_path(fused_model1, fuseable_layer_attribute[1])\n",
    "        if isinstance(bn_layer, nn.Identity):\n",
    "            continue\n",
    "        # Fuse conv and bn layers\n",
    "        fused_layer = fuse_conv_and_bn(conv_layer, bn_layer)\n",
    "        num_conv_params = sum(p.numel() for p in conv_layer.parameters())\n",
    "        num_bn_params = sum(p.numel() for p in bn_layer.parameters())\n",
    "        num_fused_params = sum(p.numel() for p in fused_layer.parameters())\n",
    "        params_reduced += num_conv_params + num_bn_params - num_fused_params\n",
    "        rsetattr(fused_model1, fuseable_layer_attribute[0], fused_layer)\n",
    "        rsetattr(fused_model1, fuseable_layer_attribute[1], nn.Identity())\n",
    "        feasible_cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"Fusion completed: BatchNorm fusion finished. {params_reduced} parameters were reduced after fusion. Feasible fused: {feasible_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feasible_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.randn((1, 3, 224, 224))\n",
    "model.eval()\n",
    "fused_model.eval()\n",
    "fused_model1.eval()\n",
    "out1 = fused_model(dummy)\n",
    "out2 = model(dummy)\n",
    "out3 = fused_model(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out1, out3, atol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1.4178943634033203\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for _ in range(20):\n",
    "    model(dummy)\n",
    "end = time.time()\n",
    "print(f\"Duration: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1.4924664497375488\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for _ in range(20):\n",
    "    fused_model(dummy)\n",
    "end = time.time()\n",
    "print(f\"Duration: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 1.4566829204559326\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for _ in range(20):\n",
    "    fused_model1(dummy)\n",
    "end = time.time()\n",
    "print(f\"Duration: {end - start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
